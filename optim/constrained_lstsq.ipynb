{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proximal_operators_and_gradients import (\n",
    "    gen_matrices, proj_linf_annulus, proj_simplex, proj_l1_ball)\n",
    "from numpy.linalg import norm, inv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-perth",
   "metadata": {},
   "source": [
    "# Grad simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_grad_dirty(mat, vec, err_max, ite_max):\n",
    "    dim = len(mat)\n",
    "    sqr = np.matmul(mat.T, mat)\n",
    "    eta = 1 / norm(sqr)  # mat is not zero\n",
    "    mul_mat = np.eye(dim) - eta * sqr\n",
    "    out = eta * np.matmul(mat.T, vec)\n",
    "    prim = np.zeros(dim)\n",
    "    err = err_max + 1\n",
    "    ite = 0\n",
    "    errs = list()\n",
    "    while err > err_max and ite < ite_max:\n",
    "        prim_new = proj_simplex(np.matmul(mul_mat, prim) + out, 1)\n",
    "        err = norm(prim - prim_new)\n",
    "        errs.append([err, norm(mat @ prim_new - vec)])\n",
    "        prim = prim_new.copy()\n",
    "        ite += 1\n",
    "    return prim, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat, vec = gen_matrices(1000)[0:2]\n",
    "res, errs = proj_grad_dirty(mat, vec, 1e-5, 10000)\n",
    "errs = np.array(errs)\n",
    "errs[:, 1] = errs[:, 1] - errs[-1, 1]\n",
    "plt.plot(np.log(errs))\n",
    "res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_grad_simplex(mat, vec, rad=1, err_max=1e-5, ite_max=1000):\n",
    "    dim = len(mat)\n",
    "    sqr = np.matmul(mat.T, mat)\n",
    "    eta = 1 / norm(sqr)  # mat is not zero\n",
    "    mul_mat = np.eye(dim) - eta * sqr\n",
    "    out = eta * np.matmul(mat.T, vec)\n",
    "    prim = np.zeros(dim)\n",
    "    err = err_max + 1\n",
    "    ite = 0\n",
    "    errs = list()\n",
    "    while err > err_max and ite < ite_max:\n",
    "        prim_new = proj_simplex(np.matmul(mul_mat, prim) + out, rad)\n",
    "        err = norm(prim - prim_new)\n",
    "        errs.append(err)\n",
    "        prim = prim_new.copy()\n",
    "        ite += 1\n",
    "    return prim, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mat, vec = gen_matrices(1000)[0:2]\n",
    "res, errs = proj_grad_simplex(mat, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-institution",
   "metadata": {},
   "source": [
    "# Grad admm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_admm_dirty(mat, vec, rad_1, rad_infty, err_max, ite_max):\n",
    "    dim = len(mat)\n",
    "    sqr = np.matmul(mat.T, mat)\n",
    "    eta = 1 / norm(sqr)  # mat is not zero\n",
    "    mul_mat = np.eye(dim) - eta * sqr\n",
    "    out = eta * np.matmul(mat.T, vec)\n",
    "    concensus = np.zeros(dim)\n",
    "    dual_1 = np.zeros(dim)\n",
    "    dual_2 = np.zeros(dim)\n",
    "#     v_min = -rad_infty\n",
    "#     v_max = +rad_infty\n",
    "    err = err_max + 1\n",
    "    ite = 0\n",
    "    errs = list()\n",
    "    while err > err_max and ite < ite_max:\n",
    "        prim = np.matmul(mul_mat, concensus) + out\n",
    "        prim_1 = proj_linf_annulus(\n",
    "            concensus - dual_1, -rad_infty, +rad_infty)\n",
    "        prim_2 = proj_l1_ball(concensus - dual_2, rad_1)\n",
    "        concensus_new = 1 / 3 * (prim + prim_1 + prim_2)\n",
    "        dual_1_new = dual_1 + prim_1 - concensus\n",
    "        dual_2_new = dual_2 + prim_2 - concensus\n",
    "        err_prim = [\n",
    "            norm(concensus_new - prim),\n",
    "            norm(concensus_new - prim_1),\n",
    "            norm(concensus_new - prim_2),\n",
    "        ]\n",
    "        err_dual = [\n",
    "            norm(concensus - concensus_new),\n",
    "            norm(prim_1 - concensus),\n",
    "            norm(prim_2 - concensus)]\n",
    "        err = max(err_prim + err_dual)\n",
    "        errs.append(err_prim + err_dual + [norm(mat @ concensus - vec)])\n",
    "        concensus = concensus_new.copy()\n",
    "        dual_1 = dual_1_new.copy()\n",
    "        dual_2 = dual_2_new.copy()\n",
    "        ite += 1\n",
    "    return concensus, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat, vec = gen_matrices(1000)[0:2]\n",
    "res, errs = grad_admm_dirty(mat, vec, 1, 0.005, 1e-5, 10000)\n",
    "errs = np.array(errs)\n",
    "errs[:, -1] = errs[:, -1] - errs[-1, -1]\n",
    "pd.DataFrame(errs).apply(np.log).plot()\n",
    "# plt.plot(np.log(errs))\n",
    "np.abs(res).max(), np.abs(res).sum()  # , res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-fancy",
   "metadata": {},
   "source": [
    "# Proximal concensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prox_quad(mat, vec, rho):\n",
    "    inv_reg = inv(np.eye(len(mat)) + rho * np.matmul(mat.T, mat))\n",
    "    out = rho * np.matmul(inv_reg, np.matmul(mat.T, vec))\n",
    "    return inv_reg, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rho_admm(\n",
    "    rho, duals, err_prim, err_dual, mat, vec, mul_mat, out, tau, ratio_max):\n",
    "    ratio_errs = err_prim / err_dual\n",
    "    if ratio_errs > ratio_max:\n",
    "        rho *= tau\n",
    "        duals = [dual / tau for dual in duals]\n",
    "        mul_mat, out = compute_prox_quad(mat, vec, rho)\n",
    "    elif ratio_errs < 1 / ratio_max:\n",
    "        rho /= tau\n",
    "        duals = [dual * tau for dual in duals]\n",
    "        mul_mat, out = compute_prox_quad(mat, vec, rho)\n",
    "    return rho, duals, mul_mat, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concensus_admm_dirty(\n",
    "    mat, vec, rad_1, rad_infty, err_max=1e-5, ite_max=1000):\n",
    "    rho = 1\n",
    "    dim = len(mat)\n",
    "    mul_mat, out = compute_prox_quad(mat, vec, rho)\n",
    "    concensus = np.random.randn(dim)\n",
    "    duals = [np.zeros(dim) for _ in range(3)]\n",
    "    err = err_max + 1\n",
    "    ite = 0\n",
    "    errs = list()\n",
    "    while err > err_max and ite < ite_max:\n",
    "        prims = np.array([\n",
    "            np.matmul(mul_mat, concensus - duals[0]) + out,\n",
    "            proj_linf_annulus(\n",
    "                concensus - duals[1], -rad_infty, +rad_infty),\n",
    "            proj_l1_ball(concensus - duals[2], rad_1)\n",
    "        ])\n",
    "        concensus_new = prims.mean(axis=0)\n",
    "        duals_new = [\n",
    "            dual + prim - concensus_new\n",
    "            for dual, prim in zip(duals, prims)]       \n",
    "        err_prim = norm(concensus - concensus_new)\n",
    "        err_dual = rho * np.array([\n",
    "            norm(prim - concensus_new) for prim in prims]).mean()\n",
    "        err = max(err_prim, err_dual)\n",
    "        errs.append([err_prim, err_dual] + [\n",
    "            norm(mat @ concensus_new - vec), rho])\n",
    "        rho, duals, mul_mat, out = update_rho_admm(\n",
    "            rho, duals, err_prim, err_dual,\n",
    "            mat, vec, mul_mat, out, 10, 100)\n",
    "        concensus = concensus_new.copy()\n",
    "        duals = [dual_new.copy() for dual_new in duals_new]\n",
    "        ite += 1\n",
    "    return concensus, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-compact",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat, vec = gen_matrices(1000)[0:2]\n",
    "res, errs = concensus_admm_dirty(mat, vec, 1, 0.005, 1e-5, 10000)\n",
    "errs = np.array(errs)\n",
    "# errs[:, -1] = errs[:, -2] - errs[-1, -2]\n",
    "pd.DataFrame(errs).apply(np.log).plot()\n",
    "# plt.plot(np.log(errs))\n",
    "np.abs(res).max(), np.abs(res).sum()  # , res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximal_concensus(\n",
    "    mat, vec, rad_1, rad_infty, err_max=1e-5, ite_max=10000):\n",
    "    rho = 1\n",
    "    dim = len(mat)\n",
    "    mul_mat, out = compute_prox_quad(mat, vec, rho)\n",
    "    concensus = np.random.randn(dim)\n",
    "    duals = [np.zeros(dim) for _ in range(3)]\n",
    "    err = err_max + 1\n",
    "    ite = 0\n",
    "    errs = list()\n",
    "    while err > err_max and ite < ite_max:\n",
    "        prims = np.array([\n",
    "            np.matmul(mul_mat, concensus - duals[0]) + out,\n",
    "            proj_linf_annulus(\n",
    "                concensus - duals[1], -rad_infty, +rad_infty),\n",
    "            proj_l1_ball(concensus - duals[2], rad_1)\n",
    "        ])\n",
    "        concensus_new = prims.mean(axis=0)\n",
    "        duals_new = [\n",
    "            dual + prim - concensus_new\n",
    "            for dual, prim in zip(duals, prims)]       \n",
    "        err_prim = norm(concensus - concensus_new)\n",
    "        err_dual = rho * np.array([\n",
    "            norm(prim - concensus_new) for prim in prims]).mean()\n",
    "        err = max(err_prim, err_dual)\n",
    "        errs.append([err_prim, err_dual])\n",
    "        rho, duals, mul_mat, out = update_rho_admm(\n",
    "            rho, duals, err_prim, err_dual,\n",
    "            mat, vec, mul_mat, out, 10, 100)\n",
    "        concensus = concensus_new.copy()\n",
    "        duals = [dual_new.copy() for dual_new in duals_new]\n",
    "        ite += 1\n",
    "    return concensus, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mat, vec = gen_matrices(1000)[0:2]\n",
    "res, errs = proximal_concensus(mat, vec, 1, 0.005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
